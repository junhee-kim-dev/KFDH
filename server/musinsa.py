# from selenium import webdriver
# from selenium.webdriver.common.by import By
# from selenium.webdriver.chrome.service import Service
# from selenium.webdriver.chrome.options import Options
# import time
# import os
# import requests
# import csv

# # ===================== ì €ì¥ í´ë” ì„¤ì • =====================
# IMAGE_DIR = "musinsa_images"
# os.makedirs(IMAGE_DIR, exist_ok=True)
# CSV_FILE = "musinsa_ranking.csv"

# # ===================== í¬ë¡¬ ì˜µì…˜ ì„¤ì • =====================
# chrome_options = Options()
# # chrome_options.add_argument("--headless")
# chrome_options.add_argument("--no-sandbox")
# chrome_options.add_argument("--disable-dev-shm-usage")

# service = Service("C:\\study25\\tf114\\chromedriver-win64\\chromedriver.exe")
# driver = webdriver.Chrome(service=service, options=chrome_options)

# # ===================== í˜ì´ì§€ ì ‘ì† =====================
# url = "https://www.musinsa.com/main/musinsa/ranking?storeCode=musinsa&sectionId=200&contentsId=&categoryCode=001000&subPan=product"
# driver.get(url)
# time.sleep(3)

# # ===================== ìŠ¤í¬ë¡¤ + ìƒí’ˆ ìˆ˜ì§‘ =====================
# SCROLL_STEP = 500           # í•œ ë²ˆì— ìŠ¤í¬ë¡¤í•  í”½ì…€
# SCROLL_PAUSE_TIME = 1.5     # ìŠ¤í¬ë¡¤ í›„ ëŒ€ê¸° ì‹œê°„
# collected_ids = set()
# data_list = []

# last_scroll = 0
# while True:
#     # í™”ë©´ì— ë³´ì´ëŠ” ëª¨ë“  ìƒí’ˆ ìš”ì†Œ
#     items = driver.find_elements(By.CSS_SELECTOR, 'div[data-item-id]')
    
#     for item in items:
#         try:
#             item_id = item.get_attribute("data-item-id")
#             if item_id in collected_ids:
#                 continue
#             collected_ids.add(item_id)

#             # StaleElement ëŒ€ë¹„ ì¬ì‹œë„
#             for _ in range(3):
#                 try:
#                     rank = item.get_attribute("data-item-list-index")
#                     brand = item.get_attribute("data-item-brand")
#                     name = item.find_element(By.CSS_SELECTOR, 'p[class*="line-clamp-2"]').text
#                     price = item.get_attribute("data-price")
#                     img_url = item.find_element(By.CSS_SELECTOR, 'img').get_attribute("src")
#                     break
#                 except:
#                     time.sleep(0.5)

#             # ì´ë¯¸ì§€ ì €ì¥
#             img_filename = f"{rank}_{name.replace('/', '_').replace(' ', '_')}.jpg"
#             img_path = os.path.join(IMAGE_DIR, img_filename)
#             try:
#                 img_data = requests.get(img_url).content
#                 with open(img_path, "wb") as f:
#                     f.write(img_data)
#             except:
#                 img_path = ""
            
#             data_list.append({
#                 "rank": rank,
#                 "brand": brand,
#                 "name": name,
#                 "price": price,
#                 "img_path": img_path
#             })
#         except Exception as e:
#             print(f"ìƒí’ˆ ì¶”ì¶œ ì‹¤íŒ¨: {e}")

#     # í™”ë©´ì„ ì¡°ê¸ˆì”© ìŠ¤í¬ë¡¤
#     driver.execute_script(f"window.scrollBy(0, {SCROLL_STEP});")
#     time.sleep(SCROLL_PAUSE_TIME)
    
#     new_scroll = driver.execute_script("return window.scrollY + window.innerHeight")
#     page_height = driver.execute_script("return document.body.scrollHeight")
    
#     if new_scroll >= page_height:
#         break

# # ===================== CSV ì €ì¥ =====================
# with open(CSV_FILE, "w", newline="", encoding="utf-8-sig") as f:
#     writer = csv.DictWriter(f, fieldnames=["rank", "brand", "name", "price", "img_path"])
#     writer.writeheader()
#     writer.writerows(data_list)

# print(f"ì´ {len(data_list)}ê°œ ìƒí’ˆ ìˆ˜ì§‘ ì™„ë£Œ!")
# driver.quit()
from prometheus_client import start_http_server, Counter, Summary, Gauge
import time
import os
import csv
import requests
from selenium import webdriver
from selenium.webdriver.common.by import By
from selenium.webdriver.chrome.service import Service
from selenium.webdriver.chrome.options import Options

# ===================== Prometheus Metrics ì •ì˜ =====================
# 1. ì´ í¬ë¡¤ë§ ê°œìˆ˜
CRAWL_TOTAL = Counter("musinsa_crawl_total", "ì´ í¬ë¡¤ë§ëœ ìƒí’ˆ ìˆ˜")

# 2. ì„±ê³µ / ì‹¤íŒ¨ ratio
CRAWL_SUCCESS = Counter("musinsa_crawl_success_total", "ì„±ê³µí•œ í¬ë¡¤ë§ ìˆ˜")
CRAWL_FAILURE = Counter("musinsa_crawl_failure_total", "ì‹¤íŒ¨í•œ í¬ë¡¤ë§ ìˆ˜")

# 3. í‰ê·  ê°œë‹¹ í¬ë¡¤ë§ ì‹œê°„
CRAWL_TIME = Summary("musinsa_crawl_item_seconds", "ê°œë‹¹ í¬ë¡¤ë§ ì‹œê°„ (ì´ˆ)")

# 4~5. ë„ë©”ì¸ë³„ (í˜¹ì€ ë¸Œëœë“œë³„) í†µê³„
DOMAIN_TOTAL = Counter("musinsa_domain_total", "ë„ë©”ì¸ë³„ í¬ë¡¤ë§ ê°œìˆ˜", ["brand"])
DOMAIN_SUCCESS = Counter("musinsa_domain_success_total", "ë„ë©”ì¸ë³„ ì„±ê³µ", ["brand"])
DOMAIN_FAILURE = Counter("musinsa_domain_failure_total", "ë„ë©”ì¸ë³„ ì‹¤íŒ¨", ["brand"])

# Prometheus HTTP exporter ì‹œì‘ (ê¸°ë³¸ í¬íŠ¸ 8001)
start_http_server(8001)
print("âœ… Prometheus metrics available at http://localhost:8001/metrics")

# ===================== ê¸°ì¡´ ì½”ë“œ =====================
IMAGE_DIR = "musinsa_images2"
os.makedirs(IMAGE_DIR, exist_ok=True)
CSV_FILE = "musinsa_ranking2.csv"

chrome_options = Options()
chrome_options.add_argument("--no-sandbox")
chrome_options.add_argument("--disable-dev-shm-usage")
chrome_options.add_argument("--headless")

service = Service("C:\\kdt\\server\\chromedriver-win64\\chromedriver.exe")
driver = webdriver.Chrome(service=service, options=chrome_options)

url = "https://www.musinsa.com/main/musinsa/ranking?storeCode=musinsa&sectionId=200&contentsId=&categoryCode=001000&subPan=product"
driver.get(url)
time.sleep(3)

SCROLL_STEP = 500
SCROLL_PAUSE_TIME = 1.5
collected_ids = set()
data_list = []

while True:
    items = driver.find_elements(By.CSS_SELECTOR, 'div[data-item-id]')
    
    for item in items:
        start_time = time.time()
        try:
            item_id = item.get_attribute("data-item-id")
            if item_id in collected_ids:
                continue
            collected_ids.add(item_id)

            rank = item.get_attribute("data-item-list-index")
            brand = item.get_attribute("data-item-brand")
            name = item.find_element(By.CSS_SELECTOR, 'p[class*="line-clamp-2"]').text
            price = item.get_attribute("data-price")
            img_url = item.find_element(By.CSS_SELECTOR, 'img').get_attribute("src")

            # ì´ë¯¸ì§€ ì €ì¥
            img_filename = f"{rank}_{name.replace('/', '_').replace(' ', '_')}.jpg"
            img_path = os.path.join(IMAGE_DIR, img_filename)
            img_data = requests.get(img_url).content
            with open(img_path, "wb") as f:
                f.write(img_data)

            data_list.append({
                "rank": rank,
                "brand": brand,
                "name": name,
                "price": price,
                "img_path": img_path
            })

            # ---- Prometheus ê¸°ë¡ ----
            elapsed = time.time() - start_time
            CRAWL_TOTAL.inc()
            CRAWL_SUCCESS.inc()
            DOMAIN_TOTAL.labels(brand=brand).inc()
            DOMAIN_SUCCESS.labels(brand=brand).inc()
            CRAWL_TIME.observe(elapsed)

        except Exception as e:
            CRAWL_FAILURE.inc()
            DOMAIN_FAILURE.labels(brand=brand if 'brand' in locals() else "unknown").inc()
            print(f"ìƒí’ˆ ì¶”ì¶œ ì‹¤íŒ¨: {e}")

    driver.execute_script(f"window.scrollBy(0, {SCROLL_STEP});")
    time.sleep(SCROLL_PAUSE_TIME)
    new_scroll = driver.execute_script("return window.scrollY + window.innerHeight")
    page_height = driver.execute_script("return document.body.scrollHeight")
    if new_scroll >= page_height:
        break

with open(CSV_FILE, "w", newline="", encoding="utf-8-sig") as f:
    writer = csv.DictWriter(f, fieldnames=["rank", "brand", "name", "price", "img_path"])
    writer.writeheader()
    writer.writerows(data_list)

print(f"ì´ {len(data_list)}ê°œ ìƒí’ˆ ìˆ˜ì§‘ ì™„ë£Œ!")
driver.quit()

# âœ… í¬ë¡¤ë§ ëë‚œ ë’¤ì—ë„ /metrics ê³„ì† ìœ ì§€
print("âœ… í¬ë¡¤ë§ ì™„ë£Œ! Prometheus /metrics ê³„ì† ë…¸ì¶œ ì¤‘ (Ctrl+Cë¡œ ì¢…ë£Œ)")
try:
    while True:
        time.sleep(10)
except KeyboardInterrupt:
    print("ğŸ›‘ ìˆ˜ë™ ì¢…ë£Œë¨. Prometheus ì„œë²„ ì¤‘ë‹¨.")